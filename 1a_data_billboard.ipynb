{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Country Music Lyric Analysis__\n",
    "#### Analyzing song lyrics with natural language processing and Non-negative Matrix Factorization (NMF) / Correlation Explanation (CorEx) topic models  \n",
    "<hr>  \n",
    "This project explores Country music as a genre by extracting and analyzing lyrics from songs posted on [Billboard's weekly hot 50 charts](https://www.billboard.com/archive/charts/2018/country-songs). Topic modeling, though not an exhaustive approach, proves useful in exploring music genres by allowing users to discover previously hidden themes and motifs in song lyrics. Introducing a time series element to the dataset also allows users to visualize trends in topic distributions over several decades.     \n",
    "\n",
    "In this case, the models and visualizations demonstrate how country music can in fact, be quite relatable; namely, that its lyrics represent a lot more than just beer, trucks, and women (themes commonly present in modern day bro-country). Applying CorEx / word anchors in a semi-supervised learning manner also reveals some more interesting, esoteric topics in Country music.  \n",
    "\n",
    "The project can be broken down into the following steps:  \n",
    "\n",
    "#### ***1. Data Acquisition***  \n",
    "\\- ***1a. Scrape Billboard chart archives and populate corpus of country songs***  \n",
    "\\- 1b. Scrape lyrics for each song from WikiLyrics and Genius APIs\n",
    "#### 2. Preprocessing - Lyrics / Data  \n",
    "\\- 2a. Use natural language processing and other methods to process text lyrics and data. Introduce some EDA and basic feature engineering    \n",
    "#### 3. Models / Analysis  \n",
    "\\- 3a. Apply non-negative matrix factorzation and CorEx to model topics and then analyze the results  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __1a. Data Acquisition - Billboard Country Top 50__\n",
    "\n",
    "### __Sections__  \n",
    "\n",
    "[1a1. Functions to scrape Billboard](#1a1)  \n",
    "[1a2. Scrape from Billboard](#1a2)  \n",
    "[1a3. Process / Save Data](#1a3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Imports for scraping\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from rq_config import project_4_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1a1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __1a1. Functions to scrape Billboard__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dates(first_week,weeks):\n",
    "    \"\"\"\n",
    "    Generates a list of dates to scrape from Billboard's archives\n",
    "    \n",
    "    Parameters\n",
    "    -----\n",
    "    first_week: The most recent chart week to start scraping from (e.g. 2019-05-29)\n",
    "    weeks: Total number of weeks to scrape (e.g. 104 = 2019-05-29 -> 2017-05-29)\n",
    "    \n",
    "    Returns:\n",
    "    List: List of all dates to be scraped from Billboard \n",
    "    \"\"\"\n",
    "    # Convert week to datetime format\n",
    "    week = datetime.strptime(first_week,'%Y-%m-%d')\n",
    "    interval = timedelta(days = 7)\n",
    "    alldates = []\n",
    "    i = 0\n",
    "    \n",
    "    # Create week list by going back 7 days at a time and appending to list\n",
    "    while i < weeks:\n",
    "        alldates.append(week.strftime('%Y-%m-%d'))\n",
    "        week = (week - interval)\n",
    "        i += 1\n",
    "    return alldates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_week(url):\n",
    "    \"\"\"\n",
    "    Pulls a list of songs, artist, and ranks from a single chart week in billboards archives\n",
    "    \n",
    "    Parameters\n",
    "    -----\n",
    "    url: unique week URL to be scraped (e.g. https://www.billboard.com/archive/charts/1960/r-b-hip-hop-songs/2019-05-02)\n",
    "    \n",
    "    Returns\n",
    "    -----\n",
    "    List: Concatenated list with songs, artists, ranks, and respective weeks\n",
    "    \"\"\"     \n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page,'lxml')\n",
    "    weekslist = []\n",
    "    \n",
    "    songlist = [song.text.strip() for song in soup.find_all(class_=\"chart-list-item__title-text\")]\n",
    "    artistlist = [artist.text.strip() for artist in soup.find_all(class_=\"chart-list-item__artist\")]\n",
    "    rankslist = [rank.text.strip() for rank in soup.find_all(class_=\"chart-list-item__rank\")]\n",
    "    weekslist.extend([url[-10:]]*len(songlist))\n",
    "    \n",
    "    return [songlist,artistlist,rankslist,weekslist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_billboard(first_week,last_week,url):\n",
    "    \"\"\"\n",
    "    Generate unique urls and concurrently scrape all urls using threading\n",
    "    \n",
    "    Parameters\n",
    "    -----\n",
    "    first_week: The most recent chart week that is being scraped (e.g. 2019)\n",
    "    last_week: The earliest chart week (e.g. 1959, etc.)\n",
    "    url: Specific URL from Billboard website. Can be alternated with other genres\n",
    "    \n",
    "    Returns\n",
    "    -----\n",
    "    List: Nested lists which contain data from all Billboard weekly archives that were scraped\n",
    "    \"\"\"\n",
    "    \n",
    "    # Total number of weeks to scrape\n",
    "    n_weeks = int(round((datetime.strptime(first_week,'%Y-%m-%d') - datetime.strptime(last_week,'%Y-%m-%d')).days / 7))\n",
    "    \n",
    "    # Generate list of unique URLs to scrape from Billboard\n",
    "    date_list = generate_dates(first_week,n_weeks)\n",
    "    url_list = [url + week for week in date_list]\n",
    "    \n",
    "    # Scrape html responses from Billboard\n",
    "    print(f'Scraping {len(url_list)} weeks from Billboard.')\n",
    "          \n",
    "    pool = Pool(25)\n",
    "    if __name__ == '__main__':\n",
    "        chart_data = list(tqdm(pool.imap(scrape_week,url_list),total = len(url_list)))\n",
    "        \n",
    "    pool.terminate()\n",
    "    pool.join()\n",
    "    \n",
    "    return chart_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1a2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __1a2. Scrape from Billboard weekly__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week to start scraping from\n",
    "\n",
    "first_week = '2019-05-12'\n",
    "\n",
    "# Last week to scrape\n",
    "last_week = '1959-07-23'\n",
    "\n",
    "# Scrape base url\n",
    "\n",
    "base_url = 'https://www.billboard.com/charts/country-songs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 3120 weeks from Billboard.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3120/3120 [06:02<00:00,  8.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Scrape responses - this should take a few minutes..\n",
    "\n",
    "billboard_responses = scrape_billboard(first_week,last_week,base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_df = pd.DataFrame(billboard_responses,columns = ['songs','artists','ranks','weeks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>songs</th>\n",
       "      <th>artists</th>\n",
       "      <th>ranks</th>\n",
       "      <th>weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Whiskey Glasses, Beautiful Crazy, God's Count...</td>\n",
       "      <td>[Morgan Wallen, Luke Combs, Blake Shelton, Cha...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[2019-05-12, 2019-05-12, 2019-05-12, 2019-05-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Beautiful Crazy, Whiskey Glasses, God's Count...</td>\n",
       "      <td>[Luke Combs, Morgan Wallen, Blake Shelton, Cha...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[2019-05-05, 2019-05-05, 2019-05-05, 2019-05-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Beautiful Crazy, God's Country, Eyes On You, ...</td>\n",
       "      <td>[Luke Combs, Blake Shelton, Chase Rice, Morgan...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[2019-04-28, 2019-04-28, 2019-04-28, 2019-04-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Beautiful Crazy, Here Tonight, Eyes On You, G...</td>\n",
       "      <td>[Luke Combs, Brett Young, Chase Rice, Blake Sh...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[2019-04-21, 2019-04-21, 2019-04-21, 2019-04-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Beautiful Crazy, Tequila, Here Tonight, Look ...</td>\n",
       "      <td>[Luke Combs, Dan + Shay, Brett Young, Thomas R...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[2019-04-14, 2019-04-14, 2019-04-14, 2019-04-1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               songs  \\\n",
       "0  [Whiskey Glasses, Beautiful Crazy, God's Count...   \n",
       "1  [Beautiful Crazy, Whiskey Glasses, God's Count...   \n",
       "2  [Beautiful Crazy, God's Country, Eyes On You, ...   \n",
       "3  [Beautiful Crazy, Here Tonight, Eyes On You, G...   \n",
       "4  [Beautiful Crazy, Tequila, Here Tonight, Look ...   \n",
       "\n",
       "                                             artists  \\\n",
       "0  [Morgan Wallen, Luke Combs, Blake Shelton, Cha...   \n",
       "1  [Luke Combs, Morgan Wallen, Blake Shelton, Cha...   \n",
       "2  [Luke Combs, Blake Shelton, Chase Rice, Morgan...   \n",
       "3  [Luke Combs, Brett Young, Chase Rice, Blake Sh...   \n",
       "4  [Luke Combs, Dan + Shay, Brett Young, Thomas R...   \n",
       "\n",
       "                                               ranks  \\\n",
       "0  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "1  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "2  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "3  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "4  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "\n",
       "                                               weeks  \n",
       "0  [2019-05-12, 2019-05-12, 2019-05-12, 2019-05-1...  \n",
       "1  [2019-05-05, 2019-05-05, 2019-05-05, 2019-05-0...  \n",
       "2  [2019-04-28, 2019-04-28, 2019-04-28, 2019-04-2...  \n",
       "3  [2019-04-21, 2019-04-21, 2019-04-21, 2019-04-2...  \n",
       "4  [2019-04-14, 2019-04-14, 2019-04-14, 2019-04-1...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __1a3. Process / Save Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df['title'] = [item for lst in billboard_df['songs'] for item in lst]\n",
    "tracks_df['artist'] = [item for lst in billboard_df['artists'] for item in lst]\n",
    "tracks_df['rank'] = [item for lst in billboard_df['ranks'] for item in lst]\n",
    "tracks_df['week'] = [item for lst in billboard_df['weeks'] for item in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>weeks</th>\n",
       "      <th>week_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Never More\" Quote The Raven</td>\n",
       "      <td>Stonewall Jackson</td>\n",
       "      <td>1969-08-03,1969-07-27,1969-07-20,1969-07-13,19...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"You've Got\" The Touch</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1987-04-26,1987-04-19,1987-04-12,1987-04-05,19...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'57 Chevrolet</td>\n",
       "      <td>Billie Jo Spears</td>\n",
       "      <td>1978-10-15,1978-10-08,1978-10-01,1978-09-24,19...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Cause I Have You</td>\n",
       "      <td>Wynn Stewart</td>\n",
       "      <td>1967-10-22,1967-10-15,1967-10-08,1967-10-01,19...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Fore She Was Mama</td>\n",
       "      <td>Clay Walker</td>\n",
       "      <td>2007-03-18,2007-03-11,2007-03-04,2007-02-25,20...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'Gator Hollow</td>\n",
       "      <td>Lefty Frizzell</td>\n",
       "      <td>1965-01-17,1965-01-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'Round Here</td>\n",
       "      <td>Sawyer Brown</td>\n",
       "      <td>1996-02-25,1996-02-18,1996-02-11,1996-02-04,19...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'Tater Raisin' Man</td>\n",
       "      <td>Dick Curless</td>\n",
       "      <td>1965-11-14,1965-11-07,1965-10-31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'Til A Tear Becomes A Rose</td>\n",
       "      <td>Keith Whitley &amp; Lorrie Morgan</td>\n",
       "      <td>1990-11-11,1990-11-04,1990-10-28,1990-10-21,19...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'Til A Tear Becomes A Rose</td>\n",
       "      <td>Leon Everette</td>\n",
       "      <td>1985-11-10,1985-11-03,1985-10-27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'Til I Get It Right</td>\n",
       "      <td>Tammy Wynette</td>\n",
       "      <td>1973-04-01,1973-03-25,1973-03-18,1973-03-11,19...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>'Til Nothing Comes Between Us</td>\n",
       "      <td>John Michael Montgomery</td>\n",
       "      <td>2003-01-12,2003-01-05,2002-12-29,2002-12-22,20...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'Til Summer Comes Around</td>\n",
       "      <td>Keith Urban</td>\n",
       "      <td>2010-04-25,2010-04-18,2010-04-11,2010-04-04,20...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'Til The Old Wears Off</td>\n",
       "      <td>The Shooters</td>\n",
       "      <td>1987-07-12,1987-07-05,1987-06-28</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'Til You Cry</td>\n",
       "      <td>Eddy Raven</td>\n",
       "      <td>1989-03-19,1989-03-12,1989-03-05,1989-02-26,19...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'Till The Water Stops Runnin'</td>\n",
       "      <td>Billy \"Crash\" Craddock</td>\n",
       "      <td>1973-12-02,1973-11-25,1973-11-18,1973-11-11,19...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'round The World With Rubber Duck</td>\n",
       "      <td>C.W. McCall</td>\n",
       "      <td>1977-01-23,1977-01-16,1977-01-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'til I Can Make It On My Own</td>\n",
       "      <td>Tammy Wynette</td>\n",
       "      <td>1976-05-09,1976-05-02,1976-04-25,1976-04-18,19...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'til I Gain Control Again</td>\n",
       "      <td>Crystal Gayle</td>\n",
       "      <td>1983-03-06,1983-02-27,1983-02-20,1983-02-13,19...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'til You're Gone</td>\n",
       "      <td>Barbara Mandrell</td>\n",
       "      <td>1982-08-08,1982-08-01,1982-07-25,1982-07-18,19...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title                         artist  \\\n",
       "0        \"Never More\" Quote The Raven              Stonewall Jackson   \n",
       "1              \"You've Got\" The Touch                        Alabama   \n",
       "2                       '57 Chevrolet               Billie Jo Spears   \n",
       "3                   'Cause I Have You                   Wynn Stewart   \n",
       "4                  'Fore She Was Mama                    Clay Walker   \n",
       "5                       'Gator Hollow                 Lefty Frizzell   \n",
       "6                         'Round Here                   Sawyer Brown   \n",
       "7                  'Tater Raisin' Man                   Dick Curless   \n",
       "8          'Til A Tear Becomes A Rose  Keith Whitley & Lorrie Morgan   \n",
       "9          'Til A Tear Becomes A Rose                  Leon Everette   \n",
       "10                'Til I Get It Right                  Tammy Wynette   \n",
       "11      'Til Nothing Comes Between Us        John Michael Montgomery   \n",
       "12           'Til Summer Comes Around                    Keith Urban   \n",
       "13             'Til The Old Wears Off                   The Shooters   \n",
       "14                       'Til You Cry                     Eddy Raven   \n",
       "15      'Till The Water Stops Runnin'         Billy \"Crash\" Craddock   \n",
       "16  'round The World With Rubber Duck                    C.W. McCall   \n",
       "17       'til I Can Make It On My Own                  Tammy Wynette   \n",
       "18          'til I Gain Control Again                  Crystal Gayle   \n",
       "19                   'til You're Gone               Barbara Mandrell   \n",
       "\n",
       "                                                weeks  week_count  \n",
       "0   1969-08-03,1969-07-27,1969-07-20,1969-07-13,19...           7  \n",
       "1   1987-04-26,1987-04-19,1987-04-12,1987-04-05,19...          15  \n",
       "2   1978-10-15,1978-10-08,1978-10-01,1978-09-24,19...           9  \n",
       "3   1967-10-22,1967-10-15,1967-10-08,1967-10-01,19...          14  \n",
       "4   2007-03-18,2007-03-11,2007-03-04,2007-02-25,20...          25  \n",
       "5                               1965-01-17,1965-01-10           2  \n",
       "6   1996-02-25,1996-02-18,1996-02-11,1996-02-04,19...          12  \n",
       "7                    1965-11-14,1965-11-07,1965-10-31           3  \n",
       "8   1990-11-11,1990-11-04,1990-10-28,1990-10-21,19...          16  \n",
       "9                    1985-11-10,1985-11-03,1985-10-27           3  \n",
       "10  1973-04-01,1973-03-25,1973-03-18,1973-03-11,19...          13  \n",
       "11  2003-01-12,2003-01-05,2002-12-29,2002-12-22,20...          25  \n",
       "12  2010-04-25,2010-04-18,2010-04-11,2010-04-04,20...          23  \n",
       "13                   1987-07-12,1987-07-05,1987-06-28           3  \n",
       "14  1989-03-19,1989-03-12,1989-03-05,1989-02-26,19...          15  \n",
       "15  1973-12-02,1973-11-25,1973-11-18,1973-11-11,19...          13  \n",
       "16                   1977-01-23,1977-01-16,1977-01-09           3  \n",
       "17  1976-05-09,1976-05-02,1976-04-25,1976-04-18,19...          12  \n",
       "18  1983-03-06,1983-02-27,1983-02-20,1983-02-13,19...          14  \n",
       "19  1982-08-08,1982-08-01,1982-07-25,1982-07-18,19...          15  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are ~300,000 songs. However, there are duplicates as many songs have repeat appearances on the popcharts. Therefore, flatten current list of scraped songs and append with new \"count\" column so we are not losing track of repeat appearances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by unique track, then flatten with new column of all aggregated weeks\n",
    "\n",
    "tracks_df = (tracks_df.groupby(['title','artist'])\n",
    "             ['week'].apply(','.join)\n",
    "             .reset_index(name='weeks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df['week_count'] = tracks_df['weeks'].apply(lambda x: len(x.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12375, 4)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(project_4_path,'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df.to_pickle(data_dir + 'tracks_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
